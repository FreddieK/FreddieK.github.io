---
layout: post
title: Collaborative Filtering - IICF - Week 4
excerpt_separator:  <!--more-->
comments: true
tags: ['Recommender Systems', 'Collaborative Filtering', 'IICF']
---

Advanced Collaborative Filtering Topics

<!--more-->


## Cold Start Problem
* There are multiple kinds
  * New users
  * New items
  * New system

### Problem: Lack of user profile/preferences
Fallback might be to use non-personalized recommendations based on popularity or demographics. Starting with these recommendations and get feedback from the user can also be a good way to start building up the user profile.

Similarly, item related recommendations based on for example product association can still be used, as well as other context based recommendations not relying on user profiles.

As you start building up a good user profile, you might start to phase out the non-personalized recommendations.

### New items
Without any data on new items, collaborative filtering won't work. A fallback might be to fallback to content-based approaches as an early proxy. Another strategy might be to recommend the items to a random, or specific, set of users to actively start trying to get feedback on the items.

### New System
Getting syndicated data from another source can help having a starting point for the system even before actual users and interactions comes in.

Similarly, if you have a system already, you might start gather data in advance of actually implementing the recommender.

## Recommending for groups
Example given is music playing in a gym, or recommending a meeting time based on multiple peoples availability.

## Threat models
* Protect somethign (important to the recommender or its users)
  * From _someone_ who has _goals_ and certain _capabilities_

### Examples
* Protect accuracy and neutrality from malicious users who want to manipulate the system
  * Solution
    * Require users to prove themselves with thresholds before their input is used.
    * Alternatively, just reactively remove data that is determined to be manipulated
* Protect user privacy from other users of the system, via reverse engineering the recommendations based on the Pearson correlation
  * Mitigation
    * Use less transparent algorithm

...

## Explaining Recommendations
* Why is this recommended?
* People tend to like simple explanations
* This felt transparency helps users feel in control
